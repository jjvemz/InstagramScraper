# ğŸ“¸ Instagram Scraper

Un scraper automatizado de Instagram desarrollado en Python que permite extraer metadatos y comentarios de publicaciones utilizando la API de Scrapfly.

## ğŸš€ Inicio RÃ¡pido

```bash
# 1. Clonar y navegar
git clone https://github.com/tu-usuario/InstagramScraper.git
cd InstagramScraper

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar credenciales
cp .env.example .env
# Editar .env con tu API key de Scrapfly

# 4. Ejecutar
python src/scraper_instagram.py
```

## âœ¨ CaracterÃ­sticas

- **ExtracciÃ³n de datos completa**: Obtiene metadatos de publicaciones, reels y videos de Instagram
- **InformaciÃ³n del usuario**: Nombre, handle, URL del perfil y estadÃ­sticas
- **Datos de engagement**: Likes, shares, comentarios con informaciÃ³n detallada
- **ExportaciÃ³n mÃºltiple**: Soporta formatos CSV y Excel (XLSX)
- **Procesamiento por lotes**: Hasta 10 URLs por ejecuciÃ³n
- **ValidaciÃ³n automÃ¡tica**: Verifica URLs de Instagram antes del procesamiento
- **Estructura organizada**: Archivos guardados con fecha y organizados por carpetas

## ğŸ› ï¸ Requisitos

### Software necesario
- Python 3.7 o superior
- Cuenta activa en [Scrapfly](https://scrapfly.io/) con API key vÃ¡lida

### Dependencias
Las dependencias se instalan automÃ¡ticamente desde `requirements.txt`:
- `requests` - Para realizar peticiones HTTP
- `scrapfly-sdk` - SDK oficial de Scrapfly
- `openpyxl` - Para generar archivos Excel
- `beautifulsoup4` - Para parsing HTML (uso futuro)
- `lxml` - Parser XML/HTML
- `python-dateutil` - Manejo de fechas
- `python-dotenv` - Para manejo de variables de entorno

## ğŸ“¦ InstalaciÃ³n

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/tu-usuario/InstagramScraper.git
   cd InstagramScraper
   ```

2. **Crear entorno virtual** (recomendado):
   ```bash
   python -m venv venv
   
   # En Windows
   venv\Scripts\activate
   
   # En macOS/Linux  
   source venv/bin/activate
   ```

3. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar Variables de Entorno**:
   - RegÃ­strate en [Scrapfly](https://scrapfly.io/) y obtÃ©n tu API key
   - **Copia el archivo de ejemplo**:
     ```bash
     # En Windows
     copy .env.example .env
     
     # En macOS/Linux
     cp .env.example .env
     ```
   - **Edita el archivo `.env`** con tus credenciales reales:
     ```bash
     SCRAPFLY_API_KEY=scp-live-tu-clave-real-aqui
     ```

## ğŸš€ Uso

### MÃ©todo 1: Ejecutar directamente
```bash
python src/scraper_instagram.py
```

### MÃ©todo 2: Script por lotes (Windows)
```bash
run_scraper.bat
```

### Flujo de trabajo:
1. **Cantidad de URLs**: Ingresa cuÃ¡ntos enlaces procesarÃ¡s (mÃ¡ximo 10)
2. **URLs de Instagram**: Proporciona las URLs una por una
3. **Formato de salida**: Elige entre CSV o XLSX
4. **Procesamiento**: El scraper extraerÃ¡ los datos automÃ¡ticamente
5. **Resultados**: Los archivos se guardan en `scrape/instagram/`

## ğŸ“ Estructura del Proyecto

```
InstagramScraper/
â”‚
â”œâ”€â”€ src/                           # CÃ³digo fuente
â”‚   â”œâ”€â”€ helpers/                   # MÃ³dulos auxiliares
â”‚   â”‚   â”œâ”€â”€ common.py             # ConfiguraciÃ³n y utilidades
â”‚   â”‚   â”œâ”€â”€ export_csv.py         # Exportador CSV
â”‚   â”‚   â””â”€â”€ export_excel.py       # Exportador Excel
â”‚   â””â”€â”€ scraper_instagram.py      # Script principal
â”‚
â”œâ”€â”€ scrape/                        # Archivos exportados
â”‚   â””â”€â”€ instagram/                 # Datos de Instagram por fecha
â”‚
â”œâ”€â”€ .env                          # Variables de entorno (NO subir a Git)
â”œâ”€â”€ .env.example                   # Plantilla de configuraciÃ³n (sÃ­ en Git)
â”œâ”€â”€ .gitignore                     # Archivos excluidos de Git
â”œâ”€â”€ requirements.txt               # Dependencias Python
â”œâ”€â”€ run_scraper.bat               # Script ejecutor Windows
â””â”€â”€ README.md                     # Esta documentaciÃ³n
```

## ğŸ“Š Datos ExtraÃ­dos

### Metadatos de PublicaciÃ³n:
- `post_url`: URL de la publicaciÃ³n
- `publisher_nickname`: Nombre del usuario
- `publisher_handle`: Handle (@usuario)
- `publisher_url`: URL del perfil
- `publish_time`: Fecha y hora de publicaciÃ³n
- `post_likes`: NÃºmero de likes
- `post_shares`: NÃºmero de compartidos
- `description`: DescripciÃ³n/caption de la publicaciÃ³n
- `total_comments_actual`: Comentarios extraÃ­dos
- `total_comments_platform`: Total segÃºn la plataforma

### Datos de Comentarios:
- `comment_number`: NÃºmero secuencial del comentario
- `nickname`: Nombre del usuario que comenta
- `user_handle`: Handle del usuario
- `user_url`: URL del perfil del usuario
- `comment_text`: Texto del comentario
- `time`: Fecha del comentario
- `likes`: Likes del comentario
- `profile_pic_url`: URL de foto de perfil
- `followers`: NÃºmero de seguidores
- `is_2nd_level`: Si es respuesta a otro comentario
- `user_replied_to`: Usuario al que responde
- `num_replies`: NÃºmero de respuestas

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno
El proyecto usa archivos de configuraciÃ³n de entorno para manejar credenciales de forma segura:

#### Archivos de configuraciÃ³n:
- **`.env.example`**: Plantilla con valores de ejemplo (incluida en Git)  
- **`.env`**: Archivo real con tus credenciales (excluido de Git)

#### ConfiguraciÃ³n inicial:
```bash
# 1. Copia el archivo de ejemplo
cp .env.example .env

# 2. Edita .env con tus valores reales
SCRAPFLY_API_KEY=scp-live-tu-clave-real-aqui
```

**ğŸ”’ Seguridad**: El archivo `.env` con tus credenciales reales estÃ¡ automÃ¡ticamente excluido del repositorio por `.gitignore`.

### PersonalizaciÃ³n de ExtracciÃ³n
El archivo `scraper_instagram.py` contiene la lÃ³gica de scraping. Puedes modificar:
- Selectores HTML para extraer datos especÃ­ficos
- Campos de datos recolectados
- LÃ³gica de procesamiento de comentarios

## ğŸ“„ Formatos de ExportaciÃ³n

### CSV
- Formato ligero y universal
- Compatible con Excel y herramientas de anÃ¡lisis
- Ideal para procesamiento de grandes volÃºmenes

### Excel (XLSX)
- Formato profesional con estilos
- SeparaciÃ³n visual entre metadatos y comentarios
- Mejor para presentaciones y reportes

## ğŸš¨ Consideraciones Importantes

### âš–ï¸ Legal y Ã‰tica
- **Respeta los tÃ©rminos de servicio de Instagram**
- **Usa de manera responsable y Ã©tica**
- **Respeta la privacidad de los usuarios**
- **No hagas scraping excesivo**
- **Considera obtener permisos cuando sea necesario**

### ğŸ”§ Limitaciones TÃ©cnicas
- Instagram cambia frecuentemente su estructura
- LÃ­mite de 10 URLs por ejecuciÃ³n
- Requiere clave API activa de Scrapfly
- Algunos datos pueden requerir ajustes en el cÃ³digo

### ğŸ”’ Seguridad
- **El archivo `.env` estÃ¡ automÃ¡ticamente excluido del repositorio**
- Nunca hardcodees claves API en el cÃ³digo
- MantÃ©n tu archivo `.env` seguro y privado
- Usa variables de entorno para todas las credenciales
- Revisa que `.env` estÃ© en `.gitignore` antes de hacer commit

## ğŸ›¡ï¸ SoluciÃ³n de Problemas

### Error: "Invalid API key" o "No se encontrÃ³ SCRAPFLY_API_KEY"
- **Archivo `.env` no existe**: Copia `.env.example` a `.env` usando `cp .env.example .env`
- **Variable no configurada**: Edita `.env` y asegÃºrate de que `SCRAPFLY_API_KEY` tenga tu clave real
- **Clave invÃ¡lida**: Verifica tu API key en el dashboard de Scrapfly
- **Sin crÃ©ditos**: Confirma que tienes crÃ©ditos disponibles en tu cuenta Scrapfly

### Error: "No se pudo scrapear nada"
- Verifica que las URLs sean pÃºblicas y vÃ¡lidas
- Revisa tu conexiÃ³n a internet
- Confirma que las URLs contengan "instagram"

### Problemas de instalaciÃ³n
- Actualiza pip: `pip install --upgrade pip`
- Usa Python 3.7+
- Crea un entorno virtual limpio

## ğŸ“ˆ Desarrollo Futuro

### Mejoras Planeadas:
- [ ] Soporte para Stories de Instagram
- [ ] ExtracciÃ³n de hashtags y menciones
- [ ] AnÃ¡lisis de engagement automÃ¡tico
- [ ] IntegraciÃ³n con bases de datos
- [ ] API REST para uso remoto
- [ ] Dashboard web con visualizaciones

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para contribuir:

1. Haz fork del repositorio
2. Crea una rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### Pautas de ContribuciÃ³n:
- Sigue las convenciones de cÃ³digo existentes
- Agrega tests para nuevas funcionalidades
- Actualiza la documentaciÃ³n
- Respeta los tÃ©rminos de uso de las plataformas

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## âš ï¸ Disclaimer

Este software estÃ¡ destinado Ãºnicamente para fines educativos y de investigaciÃ³n. Los usuarios son responsables de cumplir con:

- TÃ©rminos de servicio de Instagram
- Leyes de privacidad y protecciÃ³n de datos
- Regulaciones locales sobre web scraping
- PolÃ­ticas de uso Ã©tico de datos

El uso indebido de esta herramienta es responsabilidad exclusiva del usuario.

## ğŸ†˜ Soporte

Si encuentras problemas o tienes preguntas:

1. Revisa la secciÃ³n de [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
2. Busca en los [Issues](https://github.com/tu-usuario/InstagramScraper/issues) existentes
3. Crea un nuevo issue con:
   - DescripciÃ³n detallada del problema
   - Pasos para reproducir el error
   - InformaciÃ³n del sistema y versiÃ³n de Python
   - Logs de error si estÃ¡n disponibles

---

**Desarrollado con â¤ï¸ para la comunidad de anÃ¡lisis de datos**

*Â¿Te gusta este proyecto? Â¡Dale una estrella â­ en GitHub!*